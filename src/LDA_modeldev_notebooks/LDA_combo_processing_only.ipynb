{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7017a5ab-7c67-4dfa-a72e-a0f50f9bf684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up sys\n",
    "import os, sys\n",
    "sys.path.append('../PMC_func')\n",
    "\n",
    "\n",
    "#python basics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "#spacy stuff\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Doc\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA, DEP, LEMMA, LOWER, IS_PUNCT, IS_DIGIT, IS_SPACE, IS_STOP\n",
    "import en_core_web_sm\n",
    "\n",
    "#gensim stuff\n",
    "from gensim.models import CoherenceModel, LdaMulticore,LdaModel\n",
    "from gensim.models.callbacks import ConvergenceMetric\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis  # don't skip this\n",
    "\n",
    "#custom dependencies\n",
    "import PMC_module\n",
    "\n",
    "#other\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea40125-e2f1-433f-907b-171ad5a06dc7",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f55eb5-9d33-43b3-b9c9-41aae4ef90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "path = '/Users/pedrogalarza/Documents/NYU-MSDS/2021_police-misconduct/misclass'\n",
    "narratives_path = os.path.join(path, 'data/cpd',\"narratives.csv\")\n",
    "narratives = pd.read_csv(narratives_path)\n",
    "intake = narratives.column_name.str.contains('take')\n",
    "narratives = (narratives[intake])[[\"cr_id\", \"column_name\", \"text\"]]\n",
    "narratives = narratives.drop_duplicates()\n",
    "df = narratives[:].copy()\n",
    "df_list = df.text.values.tolist() #store documents as list of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328a0c6-0134-4284-8a98-5e0ea91d0ffb",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "#### Input Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf73f64-57c8-4af2-8fb5-5d92f20fea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input normalization with duplicate removal\n",
    "input_list_normalization = PMC_module.input_normalization(texts = df_list)\n",
    "df_list_normalized = input_list_normalization.normalization_lower()\\\n",
    "                                                 .normalization_whitespace()\\\n",
    "                                                     .strip_accents()\\\n",
    "                                                         .normalization_remove_repeats()\\\n",
    "                                                             .texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0e5098-2492-4241-8be7-7b4b06a1deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input normalization with out duplicate removal\n",
    "input_list_normalization_keep_repeats = PMC_module.input_normalization(texts = df_list)\n",
    "df_list_normalized_keep_repeats = input_list_normalization_keep_repeats.normalization_lower()\\\n",
    "                                                 .normalization_whitespace()\\\n",
    "                                                     .strip_accents()\\\n",
    "                                                        .texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91df6c11-0b83-448a-9c87-27838bb2017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of repeated entries: 994\n"
     ]
    }
   ],
   "source": [
    "#count number of district entries between input normalization techiques\n",
    "repeat_entry_count = sum(np.array(df_list_normalized) != np.array(df_list_normalized_keep_repeats))\n",
    "print('number of repeated entries:', repeat_entry_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36713d1e-9d06-46c7-b6f3-8ee6729df443",
   "metadata": {},
   "source": [
    "#### Spacy Filtering and Lemmatization - After Repeat Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "597ae0de-203a-4efa-8219-637696e6e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream spacy docs into lemmatization functions\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "lemmatized_texts = []\n",
    "for doc in nlp.pipe(df_list_normalized, batch_size=20):\n",
    "    spacy_tokenizer_test = PMC_module.spacy_filters(doc = doc)\n",
    "    lemmatized_doc = spacy_tokenizer_test.filter_length()\\\n",
    "                                .filter_stop()\\\n",
    "                                    .filter_punc()\\\n",
    "                                        .extract_lemmas()\\\n",
    "                                            .bag_of_lem\n",
    "\n",
    "    lemmatized_texts.append(lemmatized_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf97b8-4c87-4134-a104-60edc6f38bc4",
   "metadata": {},
   "source": [
    "#### Filter Lengths - Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e164d839-2858-43e0-a42f-c7a4f9690394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join into composite data frame\n",
    "df_lemmatized_texts = df.copy()\n",
    "df_lemmatized_texts['bag_of_lemmas'] = lemmatized_texts\n",
    "df_lemmatized_texts['BoL_length'] = df_lemmatized_texts.apply(lambda row: len(row['bag_of_lemmas']),axis=1)\n",
    "df_filtered_lemmatized_texts = df_lemmatized_texts.copy()\n",
    "df_filtered_lemmatized_texts = df_filtered_lemmatized_texts[df_filtered_lemmatized_texts['BoL_length'] >= 10]\n",
    "df_filtered_lemmatized_texts[\"row_number\"] = df_filtered_lemmatized_texts.reset_index().index\n",
    "\n",
    "#store lemmas into list for gensim processing\n",
    "nogram_list_lemmatized_texts = df_filtered_lemmatized_texts.bag_of_lemmas.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3dae1a-d7b1-4d61-a3ba-5d0d807f3556",
   "metadata": {},
   "source": [
    "#### Filter Legths - Print effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b172cf35-08f4-4008-b938-35394543a15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents before filtering bag length: 42896\n",
      "number of documents after filtering bag length: 34298\n",
      "Percentage of Remaining Vocabulary After Filtering Length: 0.7995617306975009\n"
     ]
    }
   ],
   "source": [
    "pct_remaining = len(df_filtered_lemmatized_texts)/len(df_lemmatized_texts)\n",
    "\n",
    "print('number of documents before filtering bag length:', len(df_lemmatized_texts))\n",
    "print('number of documents after filtering bag length:', len(df_filtered_lemmatized_texts))\n",
    "print(\"Percentage of Remaining Vocabulary After Filtering Length:\", pct_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3669751-32b2-47ec-af64-9e5d87ea155c",
   "metadata": {},
   "source": [
    "### Gensim Vectorizing\n",
    "#### N-gram Contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c8fd57-e8dc-4a81-8a21-c11737432338",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(nogram_list_lemmatized_texts, min_count=3, threshold=10,connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "\n",
    "bigram_list_lemmatized_texts = list(bigram[nogram_list_lemmatized_texts])\n",
    "trigram = Phrases(bigram_list_lemmatized_texts, min_count=3, threshold=10,connector_words=ENGLISH_CONNECTOR_WORDS)\n",
    "trigram_list_lemmatized_texts = list(trigram[bigram_list_lemmatized_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6276b37-edc7-40c7-b106-6a61c5f071a2",
   "metadata": {},
   "source": [
    "#### Contruct to Gensim Corpus Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75520a4-379d-422c-ae17-ba1a62f63062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Remaining Vocabulary After Filtering Extremes:  0.10256284608222668\n",
      "Percentage of Remaining Vocabulary After Filtering Extremes:  0.09265482477196352\n",
      "Percentage of Remaining Vocabulary After Filtering Extremes:  0.08382530763212177\n"
     ]
    }
   ],
   "source": [
    "corpus, id2word = PMC_module.gensim_vectorizing(nogram_list_lemmatized_texts,lower=20, upper=.8)\n",
    "bi_corpus, bi_id2word = PMC_module.gensim_vectorizing(bigram_list_lemmatized_texts,lower=20, upper=.8)\n",
    "tri_corpus, tri_id2word = PMC_module.gensim_vectorizing(trigram_list_lemmatized_texts,lower=20, upper=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d1d46-8d48-4325-8f1b-eb94baa847a2",
   "metadata": {},
   "source": [
    "#### Construct Composite Data Frame\n",
    "- Convert Gensim Processed Document Vectors into Dictionaries\n",
    "- Store Frequency dictionaries into dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "221b115d-f5dd-4c4e-a208-cd6c1b7c338f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cr_id</th>\n",
       "      <th>column_name</th>\n",
       "      <th>text</th>\n",
       "      <th>bag_of_lemmas</th>\n",
       "      <th>BoL_length</th>\n",
       "      <th>row_number</th>\n",
       "      <th>gensim_nogram</th>\n",
       "      <th>gensim_bigram</th>\n",
       "      <th>gensim_trigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049924</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>THE REPORTING PARTY, WHO DID NOT\\nWITNESS THE ...</td>\n",
       "      <td>[reporting, party, witness, incident, allege, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>{'accuse': 1, 'dog': 1, 'enter': 1, 'incident'...</td>\n",
       "      <td>{'accuse': 1, 'enter_residence': 1, 'justifica...</td>\n",
       "      <td>{'accuse': 1, 'enter_residence': 1, 'justifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1050193</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>It is reported that the accused officer failed...</td>\n",
       "      <td>[report, accuse, officer, fail, terminate, mot...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>{'accuse': 4, 'officer': 4, 'fail': 4, 'motor'...</td>\n",
       "      <td>{'accuse': 4, 'officer': 4, 'fail': 4, 'order'...</td>\n",
       "      <td>{'accuse': 4, 'officer': 4, 'fail': 4, 'order'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1050294</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>The reporting party (aD\\nalleges that he was b...</td>\n",
       "      <td>[reporting, party, ad, allege, beat, bouncer, ...</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>{'incident': 1, 'officer': 3, 'party': 5, 'rep...</td>\n",
       "      <td>{'officer': 3, 'party': 5, 'reporting': 5, 'fa...</td>\n",
       "      <td>{'officer': 3, 'party': 5, 'reporting': 5, 'fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1050294</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>The reporting party\\nalleges that an unknown o...</td>\n",
       "      <td>[reporting, party, allege, unknown, officer, t...</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>{'incident': 1, 'officer': 3, 'party': 4, 'rep...</td>\n",
       "      <td>{'officer': 3, 'party': 4, 'reporting': 4, 'fa...</td>\n",
       "      <td>{'officer': 3, 'party': 4, 'reporting': 4, 'fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1050588</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>The reporting party alleges that several\\nplai...</td>\n",
       "      <td>[reporting, party, allege, plainclothe, office...</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>{'officer': 5, 'party': 5, 'reporting': 5, 'fa...</td>\n",
       "      <td>{'officer': 5, 'party': 5, 'reporting': 5, 'fa...</td>\n",
       "      <td>{'officer': 5, 'party': 5, 'reporting': 5, 'un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77207</th>\n",
       "      <td>1069346</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>The victim alleges that her white Iphone\\nwhic...</td>\n",
       "      <td>[victim, allege, white, iphone, person, time, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>34293</td>\n",
       "      <td>{'time': 1, 'arrest': 1, 'victim': 1, 'white':...</td>\n",
       "      <td>{'time': 1, 'arrest': 1, 'victim': 1, 'white':...</td>\n",
       "      <td>{'time': 1, 'arrest': 1, 'victim': 1, 'white':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77212</th>\n",
       "      <td>1069383</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>It is reported that after the arrest of the\\nw...</td>\n",
       "      <td>[report, arrest, witness, vehicle, unknown, of...</td>\n",
       "      <td>11</td>\n",
       "      <td>34294</td>\n",
       "      <td>{'officer': 1, 'witness': 1, 'fail': 1, 'repor...</td>\n",
       "      <td>{'officer': 1, 'fail': 1, 'report': 1, 'vehicl...</td>\n",
       "      <td>{'officer': 1, 'report': 1, 'vehicle': 1, 'unk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77214</th>\n",
       "      <td>1069617</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>THE REPORTING PARTY ALLEGES THAT\\nONE THE ACCU...</td>\n",
       "      <td>[reporting, party, allege, accuse, officer, se...</td>\n",
       "      <td>34</td>\n",
       "      <td>34295</td>\n",
       "      <td>{'accuse': 2, 'justification': 1, 'officer': 2...</td>\n",
       "      <td>{'accuse': 2, 'justification': 1, 'officer': 2...</td>\n",
       "      <td>{'accuse': 2, 'justification': 1, 'officer': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77216</th>\n",
       "      <td>1069693</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>THE REPORTING PARTY ALLEGES THAT\\nTHE DEPARTME...</td>\n",
       "      <td>[reporting, party, allege, department, member,...</td>\n",
       "      <td>10</td>\n",
       "      <td>34296</td>\n",
       "      <td>{'party': 1, 'reporting': 1, 'damage': 1, 'cau...</td>\n",
       "      <td>{'party': 1, 'reporting': 1, 'damage': 1, 'cau...</td>\n",
       "      <td>{'party': 1, 'reporting': 1, 'department_membe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77218</th>\n",
       "      <td>1069745</td>\n",
       "      <td>Initial / Intake Allegation</td>\n",
       "      <td>It is reported that an unknown officer\\nfailed...</td>\n",
       "      <td>[report, unknown, officer, fail, inspect, vehi...</td>\n",
       "      <td>18</td>\n",
       "      <td>34297</td>\n",
       "      <td>{'officer': 2, 'fail': 1, 'report': 2, 'vehicl...</td>\n",
       "      <td>{'officer': 2, 'fail': 1, 'report': 2, 'vehicl...</td>\n",
       "      <td>{'officer': 2, 'fail': 1, 'report': 2, 'vehicl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34298 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cr_id                  column_name  \\\n",
       "1      1049924  Initial / Intake Allegation   \n",
       "5      1050193  Initial / Intake Allegation   \n",
       "9      1050294  Initial / Intake Allegation   \n",
       "12     1050294  Initial / Intake Allegation   \n",
       "17     1050588  Initial / Intake Allegation   \n",
       "...        ...                          ...   \n",
       "77207  1069346  Initial / Intake Allegation   \n",
       "77212  1069383  Initial / Intake Allegation   \n",
       "77214  1069617  Initial / Intake Allegation   \n",
       "77216  1069693  Initial / Intake Allegation   \n",
       "77218  1069745  Initial / Intake Allegation   \n",
       "\n",
       "                                                    text  \\\n",
       "1      THE REPORTING PARTY, WHO DID NOT\\nWITNESS THE ...   \n",
       "5      It is reported that the accused officer failed...   \n",
       "9      The reporting party (aD\\nalleges that he was b...   \n",
       "12     The reporting party\\nalleges that an unknown o...   \n",
       "17     The reporting party alleges that several\\nplai...   \n",
       "...                                                  ...   \n",
       "77207  The victim alleges that her white Iphone\\nwhic...   \n",
       "77212  It is reported that after the arrest of the\\nw...   \n",
       "77214  THE REPORTING PARTY ALLEGES THAT\\nONE THE ACCU...   \n",
       "77216  THE REPORTING PARTY ALLEGES THAT\\nTHE DEPARTME...   \n",
       "77218  It is reported that an unknown officer\\nfailed...   \n",
       "\n",
       "                                           bag_of_lemmas  BoL_length  \\\n",
       "1      [reporting, party, witness, incident, allege, ...          15   \n",
       "5      [report, accuse, officer, fail, terminate, mot...          44   \n",
       "9      [reporting, party, ad, allege, beat, bouncer, ...          74   \n",
       "12     [reporting, party, allege, unknown, officer, t...          73   \n",
       "17     [reporting, party, allege, plainclothe, office...          69   \n",
       "...                                                  ...         ...   \n",
       "77207  [victim, allege, white, iphone, person, time, ...          10   \n",
       "77212  [report, arrest, witness, vehicle, unknown, of...          11   \n",
       "77214  [reporting, party, allege, accuse, officer, se...          34   \n",
       "77216  [reporting, party, allege, department, member,...          10   \n",
       "77218  [report, unknown, officer, fail, inspect, vehi...          18   \n",
       "\n",
       "       row_number                                      gensim_nogram  \\\n",
       "1               0  {'accuse': 1, 'dog': 1, 'enter': 1, 'incident'...   \n",
       "5               1  {'accuse': 4, 'officer': 4, 'fail': 4, 'motor'...   \n",
       "9               2  {'incident': 1, 'officer': 3, 'party': 5, 'rep...   \n",
       "12              3  {'incident': 1, 'officer': 3, 'party': 4, 'rep...   \n",
       "17              4  {'officer': 5, 'party': 5, 'reporting': 5, 'fa...   \n",
       "...           ...                                                ...   \n",
       "77207       34293  {'time': 1, 'arrest': 1, 'victim': 1, 'white':...   \n",
       "77212       34294  {'officer': 1, 'witness': 1, 'fail': 1, 'repor...   \n",
       "77214       34295  {'accuse': 2, 'justification': 1, 'officer': 2...   \n",
       "77216       34296  {'party': 1, 'reporting': 1, 'damage': 1, 'cau...   \n",
       "77218       34297  {'officer': 2, 'fail': 1, 'report': 2, 'vehicl...   \n",
       "\n",
       "                                           gensim_bigram  \\\n",
       "1      {'accuse': 1, 'enter_residence': 1, 'justifica...   \n",
       "5      {'accuse': 4, 'officer': 4, 'fail': 4, 'order'...   \n",
       "9      {'officer': 3, 'party': 5, 'reporting': 5, 'fa...   \n",
       "12     {'officer': 3, 'party': 4, 'reporting': 4, 'fa...   \n",
       "17     {'officer': 5, 'party': 5, 'reporting': 5, 'fa...   \n",
       "...                                                  ...   \n",
       "77207  {'time': 1, 'arrest': 1, 'victim': 1, 'white':...   \n",
       "77212  {'officer': 1, 'fail': 1, 'report': 1, 'vehicl...   \n",
       "77214  {'accuse': 2, 'justification': 1, 'officer': 2...   \n",
       "77216  {'party': 1, 'reporting': 1, 'damage': 1, 'cau...   \n",
       "77218  {'officer': 2, 'fail': 1, 'report': 2, 'vehicl...   \n",
       "\n",
       "                                          gensim_trigram  \n",
       "1      {'accuse': 1, 'enter_residence': 1, 'justifica...  \n",
       "5      {'accuse': 4, 'officer': 4, 'fail': 4, 'order'...  \n",
       "9      {'officer': 3, 'party': 5, 'reporting': 5, 'fa...  \n",
       "12     {'officer': 3, 'party': 4, 'reporting': 4, 'fa...  \n",
       "17     {'officer': 5, 'party': 5, 'reporting': 5, 'un...  \n",
       "...                                                  ...  \n",
       "77207  {'time': 1, 'arrest': 1, 'victim': 1, 'white':...  \n",
       "77212  {'officer': 1, 'report': 1, 'vehicle': 1, 'unk...  \n",
       "77214  {'accuse': 2, 'justification': 1, 'officer': 2...  \n",
       "77216  {'party': 1, 'reporting': 1, 'department_membe...  \n",
       "77218  {'officer': 2, 'fail': 1, 'report': 2, 'vehicl...  \n",
       "\n",
       "[34298 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_lemmatized_texts[\"gensim_nogram\"] =  df_filtered_lemmatized_texts.apply(lambda row: PMC_module.corp2dict(row.row_number,corpus, id2word),axis=1)\n",
    "df_filtered_lemmatized_texts[\"gensim_bigram\"] =  df_filtered_lemmatized_texts.apply(lambda row: PMC_module.corp2dict(row.row_number,bi_corpus, bi_id2word),axis=1)\n",
    "df_filtered_lemmatized_texts[\"gensim_trigram\"] =  df_filtered_lemmatized_texts.apply(lambda row: PMC_module.corp2dict(row.row_number,tri_corpus, tri_id2word),axis=1)\n",
    "df_filtered_lemmatized_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f30995-c470-4150-b5c4-8362f336b3aa",
   "metadata": {},
   "source": [
    "#### Pickle data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd989311-ff6d-4b00-82cd-b12d6c978503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_lemmatized_texts.to_pickle(\"../pickled_data/df_lemmatized_texts.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a720a8fb-cad9-4554-b950-69bad6f66917",
   "metadata": {},
   "source": [
    "#### Pickle Text List, Gensim Corpus, and Gensim id2wrod dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac8b041-dc28-4f04-a690-f642dc1364d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nogram_filename = \"../pickled_data/nogram_corpus.pkl\"\n",
    "bigram_filename = \"../pickled_data/bigram_corpus.pkl\"\n",
    "trigram_filename = \"../pickled_data/trigram_corpus.pkl\"\n",
    "\n",
    "\n",
    "nogram_data = (nogram_list_lemmatized_texts,corpus, id2word)\n",
    "with open(nogram_filename, \"wb\") as f:\n",
    "    pickle.dump(nogram_data, f)\n",
    "\n",
    "bigram_data = (bigram_list_lemmatized_texts,bi_corpus, bi_id2word)\n",
    "with open(bigram_filename, \"wb\") as g:\n",
    "    pickle.dump(bigram_data, g)\n",
    "    \n",
    "trigram_data = (trigram_list_lemmatized_texts,tri_corpus, tri_id2word)\n",
    "with open(trigram_filename, \"wb\") as h:\n",
    "    pickle.dump(trigram_data, h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
